# -*- coding: utf-8 -*-
"""NH_final.ipynb

Automatically generated by Colaboratory.

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as pltfrom 
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import colors
#import skimage as skimage

from sklearn.cluster import KMeans

import cv2 as cv2
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px

import seaborn as sns

fungiO= cv2.imread('fungi3.jpg')##     Loads an image from a file
fungi=cv2.GaussianBlur(fungiO,(11,11), 0, 0, cv2.BORDER_DEFAULT) ## рассеяние по Гауссу, нули - стандартное отклонение. Делаем, чтоб границы стали менее дискретными
fig=px.imshow(cv2.cvtColor(fungi,cv2.COLOR_RGB2BGR)) ## конвертация цвета (конвертколор), 
fig.show()

"""# Кластеризация Kmeans"""

from time import time
from sklearn.utils import shuffle

my_init = np.array([[30.,40.,50],[60.,70.,20.],[98.,188.,153]]) #затравка для кластеризации, не используется.

fun_flt = np.array(cv2.cvtColor(fungi,cv2.COLOR_RGB2HLS), dtype=np.float64) / 255 #тип элементов массива добавился, поэтому фунги_флоат 
w, h, d = original_shape = tuple(fungi.shape) # создаем кортеж, а вот что такое d? density. Это rgb или hls компоненты w x h точек по три праметра в каждой
assert d == 3 # 
image_array = np.reshape(fun_flt, (w * h, d)) # реорганизовываем его 
print("Fitting model on a small sub-sample of the data")
t0 = time()
#image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)
#kmeans = KMeans(n_clusters=3, random_state=0).fit(image_array_sample)
#kmeans = KMeans(n_clusters=3, random_state=0).fit(image_array)
kmeans = KMeans(init=my_init,n_clusters=3,n_init=1,random_state=0).fit(image_array) #число инициализаций равно 1 чтоб результаты были нормальными, а не каждый раз разными
print(f"done in {time() - t0:0.3f}s.")

# Get labels for all points
print("Predicting color indices on the full image (k-means)")
t0 = time()
labels = kmeans.predict(image_array) # supposed to point out closest cluster for the unseen data. Из 3D делает 1мерный массив, заменяя 1-мерной точкой (0, 1, 2: номером кластера) его бывшие координаты (3-мерную цветовую точку)
print(f"done in {time() - t0:0.3f}s.")
print(kmeans.cluster_centers_*255,kmeans.inertia_)
result = kmeans.labels_.reshape(fungi.shape[0],fungi.shape[1]) #reshape data into the original image dimensions
im_list = list(kmeans.labels_) # обсудить отсюда https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
print(im_list.count(0),im_list.count(1),im_list.count(2),im_list.count(3))
fig=px.imshow(result)
fig.show()

new_mask=result==0 ### Для fungi3   ##_________!!!!!_______
new_image=result.copy()
new_image=new_image.astype(np.uint8) # Converted the datatype to np.uint8 (int	0 to 255)
new_image[new_mask]=254 # if newmask == 0 newimage = 254 else meowimage = 1
fig = px.imshow(new_image)
fig.show()

#Mask_Edged=cv2.Canny(cv2.GaussianBlur(new_image, (11,11), 0, 0, cv2.BORDER_DEFAULT),10,200)
Mask_Edged=cv2.Canny(new_image,150,255) #edge detection algorithm
fig = px.imshow(Mask_Edged) 
fig.show()

#Ячейка №5
#Image's Clour Footprints Formation (3 layers)
kernel =cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2)) # Returns a structuring element of the specified size and shape for morphological operations.  https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc
Mask_Closed_ = cv2.morphologyEx(Mask_Edged, cv2.MORPH_CLOSE, kernel, iterations = 2) #Performs advanced morphological transformations.  https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f
fig = px.imshow(Mask_Closed_)
fig.show()

#Mask_Closed_ = Mask_Edged.copy()
Color_M=[(255,0,0),(0,255,0),(0,0,255)]
Image_ = fungiO.copy()
R_=[]
result_ = cv2.cvtColor(Image_,cv2.COLOR_RGB2BGR).copy()
Cont_List = [] #лист контуров
contours, hierarchy= cv2.findContours(Mask_Closed_, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #ищем контуры, только внешние. Цепочная аппроксимация используется если контуры простые, как прямоугольники
sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True) #упорядочивание по размеру
cv2.drawContours(result_, contours,-1, Color_M[0], 2) 
for (i,c) in enumerate(sorted_contours):
    x,y,w,h= cv2.boundingRect(c) #заключаем в прямоугольник
    R_.append([x,y,w,h])
    M = cv2.moments(c)
    cx = int(M['m10']/M['m00'])
    cy = int(M['m01']/M['m00'])
    cv2.rectangle(result_,(x, y),(x+w,y+h),Color_M[2],2)
    cv2.circle(result_, (cx, cy), 5, Color_M[2], -1)
    if len(sorted_contours[i]) < 50 : break 
    else:Cont_List.append(sorted_contours[i])
plt.figure(figsize=(16,24))
plt.imshow(result_)

#Cont_List[50] #координаты меняются на 1 (или 1;1)

#Creation of Pandas dataframe form R_ list
R_dfs = pd.DataFrame(R_,columns=["x", "y", "w","h"])
#x,y и X,Y  - координаты диагонали 
R_dfs.insert(4,'X',R_dfs.x + R_dfs.w)
R_dfs.insert(5,'Y',R_dfs.y + R_dfs.h)
#R_dfs.head()
#Удаляем слишком большие прямоугольники
#R_dfsh=R_dfs.loc[R_dfs.S < 1220000]
#R_dfsh.shape
#Перенумеровываем строки - прямоугольники
#R_dfsr=R_dfsh.reset_index()

Corn_df = R_dfs.get(['x','y','X','Y'])
#Corn_df.head()
records = Corn_df.to_records()
#Это лист перекрывающих прямоугольников
Corners_List = list(records)
Corners_List[0]

#x,y - координаты верхнего левого угла
#X,Y - координаты нижнего правого угла
result_ = cv2.cvtColor(Image_,cv2.COLOR_RGB2BGR).copy()
for i_c,x_c,y_c,X_c,Y_c in Corners_List:
  cx=int((X_c-x_c)/2+x_c)
  cy=int((Y_c-y_c)/2+y_c)
  cv2.rectangle(result_,(x_c, y_c),(X_c,Y_c),Color_M[0],2)
#cv2.circle(result_, (cx, cy), 10, (255,255,255), -1)
  cv2.putText(result_, str(i_c), (cx, cy),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),3,cv2.LINE_AA)
  cv2.putText(result_, str(i_c), (cx, cy),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),1,cv2.LINE_AA)
cv2.drawContours(result_, sorted_contours[2],-1, Color_M[0], 2)  
plt.figure(figsize=(16,24))
plt.imshow(result_)

C_Num=6
Frame_= Corn_df.iloc[C_Num]
NewImage_=Image_[Frame_.y:Frame_.Y,Frame_.x:Frame_.X,:]
NewImage_L=cv2.cvtColor(NewImage_,cv2.COLOR_RGB2HLS)
#NewImage_L=cv2.cvtColor(NewImage_,cv2.COLOR_BGR2HLS)
NewImage_S=cv2.cvtColor(NewImage_,cv2.COLOR_RGB2HSV)
fig = px.imshow(cv2.cvtColor(NewImage_,cv2.COLOR_RGB2BGR))
#fig = px.imshow(cv2.cvtColor(NewImage_,cv2.COLOR_RGB2HLS))
fig.show()

from numpy.ma.core import reshape

NewRows_df=pd.DataFrame(columns=['cOunt','mEan','sTd','Q25','Q50','Q75','WH'])
#NewRows_df.head()
Dist_HLSdf=Corn_df.copy()
Dist_HLSdf=Dist_HLSdf.append(NewRows_df)
Dist_HLSdf.head()

#Функция, которая рассчитывает нормализованную гистограмму
def _Normalize (_y,_x,_Depth):
    _Output=[]
    for _i_ in range(_Depth):_Output.append(0)
    for _i_ in range (len(_y)):
        _j_= int((_x[_i_]*_Depth)/256)
        _Output[_j_]+=_y[_i_]
    return _Output/sum(_y)

#Функция, которая готовит маску для выделения содержимого контура
def CntFiller (ImAge,ConTour):
    r=[]
    for j in range (ImAge.shape[1]):
        s=[]
        for i in range (len(ConTour)):
            if (ConTour[i].item(0)== j):
                s.append(ConTour[i].item(1))
        if(len(s))>0:
            r.append(tuple([j,min(s),max(s)]))
    stencil = np.zeros(ImAge.shape).astype(ImAge.dtype)
#    print(r)
    for x,ymn,ymx in r:
        for i in range(ymn,ymx-1):
            stencil[i][x]=[255,255,255]
    return (stencil)



#############__1__###################
# Расчет гистограмм для выделенных  #
# контуров без очистки              #
#####################################
Hist_HLSdf=Corn_df.copy()
Hist_HLSdf=Dist_HLSdf.append(NewRows_df)
Vector=[]
Result=[]
for C_Num in range(len(Corn_df)):
    Frame_= Corn_df.iloc[C_Num]
    NewImage_=Image_[Frame_.y:Frame_.Y,Frame_.x:Frame_.X,:]
    NewImage_L=cv2.cvtColor(NewImage_,cv2.COLOR_RGB2HLS)
    St_l=len(NewImage_)
    Rw_l=len(NewImage_[0])
    B_RGB=NewImage_.reshape([Rw_l*St_l,3])
    H_RGBdf = pd.DataFrame(B_RGB,columns=["I", "II", "III"])
    B_HLS=NewImage_L.reshape([Rw_l*St_l,3])
    H_HLSdf = pd.DataFrame(B_HLS,columns=["I", "II", "III"])
    Hist_HLSdf.loc[C_Num,'cOunt']=H_HLSdf.I.count()
    if (H_HLSdf.I.count()>1000):
        serie_=H_HLSdf.I.value_counts(ascending=True,sort=False)
        E=_Normalize(serie_.values,serie_.index,128)
        Vector.append(C_Num)
        Result.append(list(E))


#############__2__###################
# Расчет гистограмм для выделенных  #
# контуров с очисткой окружения     #
#####################################
Hist2_HLSdf=Corn_df.copy()
Hist2_HLSdf=Hist2_HLSdf.append(NewRows_df)
Vector2=[]
Result2=[]
for C_Num in range(len(Corn_df)):
#for C_Num in [44]:
    Frame_= Corn_df.iloc[C_Num]
    NewImage_=Image_[Frame_.y:Frame_.Y,Frame_.x:Frame_.X,:]
    cnt=sorted_contours[C_Num]
# Определение смещения контура
    x_shift=int(Dist_HLSdf.x[C_Num])
    y_shift=int(Dist_HLSdf.y[C_Num])
# Сдвиг контура
    cnt_shift=cnt-[x_shift,y_shift]
    Next=CntFiller(NewImage_,cnt_shift) 
    result = cv2.bitwise_and(NewImage_, Next)
    NewImage_L=cv2.cvtColor(result,cv2.COLOR_RGB2HLS)
    St_l=len(NewImage_L)
    Rw_l=len(NewImage_L[0])
    B_HLS=NewImage_L.reshape([Rw_l*St_l,3])
    H_HLSdf = pd.DataFrame(B_HLS,columns=["I", "II", "III"])
    Hist2_HLSdf.loc[C_Num,'cOunt']=H_HLSdf.I.count()
    if (H_HLSdf.I.count()>1000):
        serie_=H_HLSdf.I.value_counts(ascending=True,sort=False)
        E=_Normalize(serie_.values,serie_.index,128)
        Vector2.append(C_Num)
        Result2.append(list(E))
        print(C_Num,' ',end=' ')
print ('Stop')

# Это номера фрагментов с грибами и без них
FunX=[1,2,3,4,5,6,7,8,10,12]
R=list(set(Vector)-set(FunX))

#Гистограмма без очистки
Histdf=pd.DataFrame(Result,index=Vector)
HdfT=Histdf.T
#Histdf

#Гистограмма с очисткой
Hist2df=pd.DataFrame(Result2,index=Vector2)
Hdf2T=Hist2df.T
Hdf2T.drop(0,inplace=True)

Hist2df.to_excel('fungi_hdb.xlsx') #Using this file for neuront testing

HdfT.plot(y=FunX,figsize=(18,5),title='Probably Fungi',xlim=(0,90))

Hdf2T.plot(y=FunX,figsize=(18,5),title='Probably Fungi (Clean)',xlim=(1,90))

HdfT.plot(y=R,figsize=(18,5),title='Probably Not Fungi',xlim=(0,90))

Hdf2T.plot(y=R,figsize=(18,5),title='Probably Not Fungi (Clean)',xlim=(1,90))

#Это для проверки выбранного фрагмента изображения с очисткой
# Номер фрагмента
#index=2
index=0
# Выбор контура
cnt=sorted_contours[index]
Frame_= Corn_df.iloc[index]
NewImage_=Image_[Frame_.y:Frame_.Y,Frame_.x:Frame_.X,:]
cnt=sorted_contours[index]
# Определение смещения контура
x_shift=int(Dist_HLSdf.x[index])
y_shift=int(Dist_HLSdf.y[index])
# Сдвиг контура
#re1=CntStretcher (x_shift,y_shift,cnt)
# Подготовка к отображению растянутого контура методами cv2
cnt_shift=cnt-[x_shift,y_shift]
Next=CntFiller(NewImage_,cnt_shift) 
result = cv2.bitwise_and(NewImage_, Next)
#result = stencil.copy()
# Логическое умножение масок
fig = px.imshow(cv2.cvtColor(result,cv2.COLOR_RGB2BGR))
result_im = cv2.cvtColor(result,cv2.COLOR_RGB2BGR)
fig.show()
#cv2.imwrite('2206.png', result)

#Корреляционная матрица по контурам без очистки
HdfT.corr()

#Корреляционная матрица по очищенным контурам
Hdf2T.corr()

#Тепловая карта по  контурам без очистки
fig, ax = plt.subplots(figsize=(16,16))
sns.heatmap(HdfT.corr(), ax=ax)
plt.show()

#Тепловая карта по очищенным контурам
fig, ax = plt.subplots(figsize=(16,16))
sns.heatmap(Hdf2T.corr(), ax=ax)
plt.show()

#############__3__###################
# Расчет гистограмм и тепловой карты#
# для выделенных                    #
# контуров без очистки, но по трем  #
# цветовым составляющим H,L и S     #
#####################################
Hist_HLSdf=Corn_df.copy()
Hist_HLSdf=Dist_HLSdf.append(NewRows_df)
Result3=[]
Vector3=[]
for C_Num in range(len(Corn_df)):
    Frame_= Corn_df.iloc[C_Num]
    NewImage_=Image_[Frame_.y:Frame_.Y,Frame_.x:Frame_.X,:]
    NewImage_L=cv2.cvtColor(NewImage_,cv2.COLOR_RGB2HLS)
    St_l=len(NewImage_)
    Rw_l=len(NewImage_[0])
    B_RGB=NewImage_.reshape([Rw_l*St_l,3])
    H_RGBdf = pd.DataFrame(B_RGB,columns=["I", "II", "III"])
    B_HLS=NewImage_L.reshape([Rw_l*St_l,3])
    H_HLSdf = pd.DataFrame(B_HLS,columns=["I", "II", "III"])
    Hist_HLSdf.loc[C_Num,'cOunt']=H_HLSdf.I.count()
    if (H_HLSdf.I.count()>1000):
        Vector3.append(C_Num)
        serie_I=H_HLSdf.I.value_counts(ascending=True,sort=False)
        EI=_Normalize(serie_I.values,serie_I.index,128)
        serie_II=H_HLSdf.II.value_counts(ascending=True,sort=False)
        EII=_Normalize(serie_II.values,serie_II.index,128)
        serie_III=H_HLSdf.III.value_counts(ascending=True,sort=False)
        EIII=_Normalize(serie_III.values,serie_III.index,128)
        E=np.concatenate((EI,EII,EIII))
        Result3.append(list(E))
Hist3df=pd.DataFrame(Result3,index=Vector3)
Hdf3T=Hist3df.T
fig, ax = plt.subplots(figsize=(16,16))
sns.heatmap(Hdf3T.corr(), ax=ax)
plt.show()


